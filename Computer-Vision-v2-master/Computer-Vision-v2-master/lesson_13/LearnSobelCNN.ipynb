{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn Sobel Filter via CNN\n",
    "\n",
    "In this notebook we will demonstrate how to train a simple CNN to learn to perform Sobel filtering (first order spatial derivatives). We will also see that a CNN can be thought of as a generic model and can be used to approximate any generic image processing algorithm. This is especially useful if a CNN-based implementation is much faster (usually with the aid of GPU or similar dedicated units) than the original algorithm implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, Input\n",
    "from tensorflow.keras import Model\n",
    "from time import time\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [15, 10]\n",
    "\n",
    "# Set the seeds for reproducibility\n",
    "from numpy.random import seed\n",
    "from tensorflow.random import set_seed\n",
    "seed_value = 1234578790\n",
    "seed(seed_value)\n",
    "set_seed(seed_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset\n",
    "\n",
    "We will try to keep it simple. Therefore, we will use one image (any image will do) and its corresponding Sobel derivative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image and convert to gray-scale\n",
    "img = cv2.imread('../lesson_5/data/kodim05.png')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Select x or y spatial derivative\n",
    "sobel = 'x'\n",
    "\n",
    "if sobel == 'x':\n",
    "    out = cv2.Sobel(img, ddepth=cv2.CV_32F, dx=1, dy=0)\n",
    "elif sobel == 'y':\n",
    "    out = cv2.Sobel(img, ddepth=cv2.CV_32F, dx=0, dy=1)\n",
    "else:\n",
    "    raise NotImplemented\n",
    "\n",
    "plt.subplot(121), plt.imshow(img, cmap='gray')\n",
    "plt.subplot(122), plt.imshow(out, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img[100:103, 100:103])\n",
    "print(out[100:103, 100:103])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Generator\n",
    "\n",
    "In this example, we will implement a data generator. So far we have been loading the entire dataset in memory and use it for training. However, in many cases, this is not possible since the dataset is simply too big to fit in memory (this is not the case of this example, though). Therefore, we will need to fetch the data batches from disk as they are requested for training purposes (the so called online fetching). For that, python provide us with the generator functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datagen(img, win=128, batch_size=16):\n",
    "    rows, cols = img.shape\n",
    "    \n",
    "    while True:\n",
    "        batch_x, batch_y = [], []\n",
    "        for _ in range(batch_size):\n",
    "            # Select any random image patch (region)\n",
    "            r_init = np.random.randint(win, rows-win)\n",
    "            c_init = np.random.randint(win, cols-win)\n",
    "            \n",
    "            # Generate inputs and labels\n",
    "            x_sample = img[r_init:r_init+win, c_init:c_init+win]\n",
    "            y_sample = out[r_init:r_init+win, c_init:c_init+win]\n",
    "            \n",
    "            # Normalize\n",
    "            x_sample = (x_sample - np.mean(x_sample))/np.std(x_sample)\n",
    "            y_sample = (y_sample - np.mean(y_sample))/np.std(y_sample)\n",
    "            \n",
    "            # Build batches\n",
    "            batch_x.append(x_sample)\n",
    "            batch_y.append(y_sample)\n",
    "            \n",
    "        yield np.array(batch_x).astype(np.float32), np.array(batch_y).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now demonstrate how data generators work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data generator\n",
    "dg = datagen(img)\n",
    "\n",
    "# Request next sample\n",
    "x, y = next(dg)\n",
    "\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Network\n",
    "\n",
    "The objective is to build a network that will learn to approximate the Sobel operator. The Sobel operator that we use in this example is the classic 3x3 kernel. Therefore, our CNN will consists of one single 3x3 convolutional kernel. And since we are interested in approximate the kernel values, we are not applying any non-linearities to the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(128, 128, 1))\n",
    "outputs = Conv2D(1, kernel_size=(3, 3), activation=\"linear\", padding='same')(inputs)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that, unlike the classic Sobel filter, the convolutional kernel includes one more parameter: the bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training\n",
    "\n",
    "Let's now train the network using the data generator. The objective funciton is the MSE (since we want the output to approximate the Sobel derivative). Furthermore, note that since we are using data generators, we need to specify the number of steps per epoch (since the generator is basically an inifinite loop providing data, the trainer does not know how long one epoch lasts)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mse\"])\n",
    "\n",
    "start = time()\n",
    "history = model.fit(dg, steps_per_epoch=1000, epochs=epochs, verbose=1)\n",
    "print('Elapsed time', time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking the Learnt Kernel\n",
    "\n",
    "We are now going to check the value of the kernel that the network has learnt. In order to do so, we are going to extract the weights and the bias fomr the (only) convolutional kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, bias = model.layers[-1].get_weights()\n",
    "print(weights, bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that the network does not know that it has to learn the exact Sobel filter (with the exact scale). Note that the output of the Sobel filter and any of its scaled versions is exactly the same (remember we have normalized the data). Therefore, in order to better visualize the learnt values, we are going to normalize the kernel so its top-left value is equal to 1 (which is true for Sobel kernels in both x and y direction)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the unit dimensions\n",
    "weights = weights.squeeze()\n",
    "\n",
    "# Normalize\n",
    "weights = weights/weights[0,0]\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation\n",
    "\n",
    "We already know that the kernel approximates quite accurately the Sobel filter. In order to visually demonstrate that, we are going to filter the input image with the learnt kernel (and sum the bias) and compare it to the original derivative image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the estimated spatial derivative using the trained filter\n",
    "est = cv2.filter2D(img, ddepth=cv2.CV_32F, kernel=weights) + bias\n",
    "\n",
    "# Compare the results\n",
    "plt.subplot(121), plt.imshow(out, cmap='gray'), plt.title('Sobel')\n",
    "plt.subplot(122), plt.imshow(est, cmap='gray'), plt.title('CNN approximation')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
